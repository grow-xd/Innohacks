{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=980x1225 at 0x2C9680349A0>\n"
     ]
    }
   ],
   "source": [
    "image_url = 'https://hips.hearstapps.com/hmg-prod/images/color-quotes44-1603314416.jpg?crop=0.96xw:1xh;center,top&resize=980:*'\n",
    "\n",
    "# Download the image\n",
    "response = requests.get(image_url)\n",
    "image_data = BytesIO(response.content)\n",
    "# Open the image using Pillow\n",
    "image = Image.open(image_data)\n",
    "\n",
    "# Display or process the image as needed\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = r'C:\\Users\\PARAM\\Desktop\\image.jpeg'\n",
    "# image = Image.open('https://media.istockphoto.com/id/1002415624/photo/new-delhi-city-in-daytime.jpg?s=612x612&w=0&k=20&c=eZkR0veckRgWRSCkBEIINfVS_aElRO7i3sFOzH-ON-A=')\n",
    "# print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text: ™ i\n",
      "\n",
      "He squints towards the dancing shrapnel of\n",
      "dying\n",
      "light along a rooftop and he says | love\n",
      "things only as they are\n",
      "and I’m sure! once did too but | can’t prove\n",
      "it to anyone these days\n",
      "and he says the end isn’t always about what\n",
      "dies and | know! know\n",
      "or | knew once and now | write about\n",
      "beautiful things\n",
      "like I will never touch a beautiful thing again\n",
      "and the man\n",
      "looks me in the yes and he points to the\n",
      "blue-orange vault\n",
      "over heaven’s gates and he says the face of\n",
      "everyone you miss\n",
      "is up there and | know! know I can’t see\n",
      "them but I know\n",
      "\n",
      "Hanif\n",
      "Willis-Abdurraqib\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_text = pytesseract.image_to_string(image)\n",
    "# extracted_text = ' '.join(word for word in extracted_text.split() if word.isalpha())\n",
    "print(\"Extracted Text:\", extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text: ™ मैं\n",
      "\n",
      "वह नाचने की छर्रे की ओर बढ़ता है\n",
      "मरना\n",
      "एक छत के साथ प्रकाश और वह कहता है |प्यार\n",
      "चीजें केवल वैसा ही हैं\n",
      "और मुझे यकीन है!एक बार भी किया लेकिन |साबित नहीं हो सकता\n",
      "यह इन दिनों किसी को भी\n",
      "और वह कहता है कि अंत हमेशा इस बारे में नहीं होता है\n",
      "मर जाता है और |जानना!जानना\n",
      "या |एक बार और अब पता था |के बारे में लिखो\n",
      "सुंदर चीजें\n",
      "जैसे मैं फिर से एक खूबसूरत चीज को कभी नहीं छूऊंगा\n",
      "और आदमी\n",
      "मुझे हाँ में दिखता है और वह इंगित करता है\n",
      "नीला-नारंगी तिजोरी\n",
      "स्वर्ग के द्वार पर और वह का चेहरा कहता है\n",
      "हर कोई आपको याद करता है\n",
      "वहाँ है और |जानना!पता है कि मैं नहीं देख सकता\n",
      "उन्हें लेकिन मुझे पता है\n",
      "\n",
      "हनीफ\n",
      "विलिस-अबदुरराकिब\n"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "# Translate the extracted text to Hindi\n",
    "translated_text = translator.translate(extracted_text, dest='hi').text\n",
    "\n",
    "print(\"Translated Text:\", translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# avg_color='black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Color (BGR): (71, 76, 34)\n"
     ]
    }
   ],
   "source": [
    "def remove_text(input_image_path, output_image_path, text_region):\n",
    "    # Load the image\n",
    "    if input_image_path.startswith('http'):\n",
    "        response = requests.get(input_image_path)\n",
    "        image = cv2.imdecode(np.frombuffer(response.content, np.uint8), cv2.IMREAD_COLOR)\n",
    "    else:\n",
    "        image = cv2.imread(input_image_path)\n",
    "\n",
    "    if image is None:\n",
    "        raise ValueError(\"Failed to load the image. Check the input path.\")\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create a binary mask using adaptive thresholding\n",
    "    _, mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Extract the region where the text is located\n",
    "    x, y, w, h = text_region\n",
    "    roi = mask[y:y+h, x:x+w]\n",
    "\n",
    "    # Check if the ROI has a valid size\n",
    "    if np.count_nonzero(roi) == 0:\n",
    "        raise ValueError(\"Text region is empty.\")\n",
    "\n",
    "    # Ensure mask and image have the same size\n",
    "    roi = cv2.resize(roi, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Inpainting to fill the text region with the surrounding background\n",
    "    result = cv2.inpaint(image, mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_image_path, result)\n",
    "\n",
    "    average_color = cv2.mean(image, mask=roi)[:3]\n",
    "    complementary_color_int = tuple(int(255 - component) for component in average_color)\n",
    "    return complementary_color_int\n",
    "\n",
    "# Example usage\n",
    "input_image_path = image_url\n",
    "output_image_path = r'C:\\Users\\PARAM\\Desktop\\img_without_txt.jpeg'\n",
    "\n",
    "# Text region (specify the coordinates and dimensions of the text region)\n",
    "text_region_coordinates = (100, 100, 200, 50)  # Example coordinates (x, y, width, height)\n",
    "\n",
    "avg_color = remove_text(input_image_path, output_image_path, text_region_coordinates)\n",
    "print(\"Text Color (BGR):\", avg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, ImageFont\n",
    "image_o = Image.open(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(image_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wrap_text(text, max_words_per_line):\n",
    "#     words = text.split()\n",
    "#     lines = []\n",
    "#     current_line = []\n",
    "\n",
    "#     for word in words:\n",
    "#         current_line.append(word)\n",
    "#         if len(current_line) == max_words_per_line:\n",
    "#             lines.append(' '.join(current_line))\n",
    "#             current_line = []\n",
    "\n",
    "#     if current_line:\n",
    "#         lines.append(' '.join(current_line))\n",
    "\n",
    "#     return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype(r\"C:\\Users\\PARAM\\Downloads\\Noto_Sans_Devanagari\\NotoSansDevanagari-VariableFont_wdth,wght.ttf\", size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_position = (30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_words_per_line = 3\n",
    "\n",
    "# # Wrap the text into lines with the specified number of words\n",
    "# wrapped_lines = wrap_text(translated_text, max_words_per_line)\n",
    "# _, _, _, baseline = font.getbbox(' ')\n",
    "# line_spacing_factor = 2\n",
    "# word_spacing_factor = 1.2\n",
    "# line_height = int(baseline * line_spacing_factor)\n",
    "# word_spacing = int(font.getbbox(' ')[2] * word_spacing_factor)\n",
    "# Draw the wrapped lines on the image\n",
    "# line_height = font.getbbox(' ')[1]  # Height of a line in the specified font\n",
    "# for line in wrapped_lines:\n",
    "draw.text(text_position, translated_text, font=font, fill=avg_color)\n",
    "    # text_position = (text_position[0], text_position[1] + line_height)\n",
    "    # text_position = (text_position[0] + word_spacing, text_position[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_o.save(r'C:\\Users\\PARAM\\Desktop\\translated.jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
